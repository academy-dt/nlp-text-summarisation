{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieltrugman/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "repo = \"facebook/bart-large-cnn\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(repo)\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(repo)\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, min_length=30, max_length=130):\n",
    "    return summarizer(text, min_length=min_length, max_length=max_length, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing text - len=7367\n",
      "\t ERROR\n",
      "Summarizing text - len=3739\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSummarizing text - len=\u001b[39m\u001b[39m{\u001b[39;00marticle_len\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=11'>12</a>\u001b[0m     summary \u001b[39m=\u001b[39m summarize(article)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=12'>13</a>\u001b[0m     output\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=13'>14</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39marticle\u001b[39m\u001b[39m'\u001b[39m: article,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=14'>15</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m: abstract,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=15'>16</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbart\u001b[39m\u001b[39m'\u001b[39m: summary[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msummary_text\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=16'>17</a>\u001b[0m     })\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=17'>18</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32m/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb Cell 3\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(text, min_length, max_length)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummarize\u001b[39m(text, min_length\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m130\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danieltrugman/Documents/Education/NLP/Repository/bart-cnn.ipynb#ch0000002?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m summarizer(text, min_length\u001b[39m=\u001b[39;49mmin_length, max_length\u001b[39m=\u001b[39;49mmax_length, do_sample\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:235\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    212\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:137\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    109\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    139\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    140\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    141\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    142\u001b[0m     ):\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/pipelines/base.py:1067\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1066\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/pipelines/base.py:1074\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1073\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1074\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1075\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1076\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/pipelines/base.py:978\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    977\u001b[0m     model_inputs[\u001b[39m\"\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m    979\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    980\u001b[0m     inference_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_inference_context()\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/pipelines/text2text_generation.py:159\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 159\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    160\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/generation_tf_utils.py:583\u001b[0m, in \u001b[0;36mTFGenerationMixin.generate\u001b[0;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m do_sample \u001b[39m=\u001b[39m do_sample \u001b[39mif\u001b[39;00m do_sample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdo_sample\n\u001b[1;32m    582\u001b[0m \u001b[39mif\u001b[39;00m do_sample \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m num_beams \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    584\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    585\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m    586\u001b[0m         max_new_tokens\u001b[39m=\u001b[39;49mmax_new_tokens,\n\u001b[1;32m    587\u001b[0m         min_length\u001b[39m=\u001b[39;49mmin_length,\n\u001b[1;32m    588\u001b[0m         do_sample\u001b[39m=\u001b[39;49mdo_sample,\n\u001b[1;32m    589\u001b[0m         early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m    590\u001b[0m         num_beams\u001b[39m=\u001b[39;49mnum_beams,\n\u001b[1;32m    591\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m    592\u001b[0m         top_k\u001b[39m=\u001b[39;49mtop_k,\n\u001b[1;32m    593\u001b[0m         top_p\u001b[39m=\u001b[39;49mtop_p,\n\u001b[1;32m    594\u001b[0m         repetition_penalty\u001b[39m=\u001b[39;49mrepetition_penalty,\n\u001b[1;32m    595\u001b[0m         bad_words_ids\u001b[39m=\u001b[39;49mbad_words_ids,\n\u001b[1;32m    596\u001b[0m         bos_token_id\u001b[39m=\u001b[39;49mbos_token_id,\n\u001b[1;32m    597\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m    598\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m    599\u001b[0m         length_penalty\u001b[39m=\u001b[39;49mlength_penalty,\n\u001b[1;32m    600\u001b[0m         no_repeat_ngram_size\u001b[39m=\u001b[39;49mno_repeat_ngram_size,\n\u001b[1;32m    601\u001b[0m         num_return_sequences\u001b[39m=\u001b[39;49mnum_return_sequences,\n\u001b[1;32m    602\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    603\u001b[0m         decoder_start_token_id\u001b[39m=\u001b[39;49mdecoder_start_token_id,\n\u001b[1;32m    604\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    605\u001b[0m         seed\u001b[39m=\u001b[39;49mmodel_kwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    606\u001b[0m         output_scores\u001b[39m=\u001b[39;49moutput_scores,\n\u001b[1;32m    607\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    608\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    609\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m    610\u001b[0m         forced_bos_token_id\u001b[39m=\u001b[39;49mforced_bos_token_id,\n\u001b[1;32m    611\u001b[0m         forced_eos_token_id\u001b[39m=\u001b[39;49mforced_eos_token_id,\n\u001b[1;32m    612\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[39m# We cannot generate if the model does not have a LM head\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_output_embeddings() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/generation_tf_utils.py:1686\u001b[0m, in \u001b[0;36mTFGenerationMixin._generate\u001b[0;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, seed, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m         model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_to_num_beams(\n\u001b[1;32m   1682\u001b[0m             model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m], num_beams\u001b[39m=\u001b[39mnum_beams\n\u001b[1;32m   1683\u001b[0m         )\n\u001b[1;32m   1685\u001b[0m     \u001b[39m# 10. run beam search\u001b[39;00m\n\u001b[0;32m-> 1686\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[1;32m   1687\u001b[0m         input_ids,\n\u001b[1;32m   1688\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   1689\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mpad_token_id,\n\u001b[1;32m   1690\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49meos_token_id,\n\u001b[1;32m   1691\u001b[0m         length_penalty\u001b[39m=\u001b[39;49mlength_penalty,\n\u001b[1;32m   1692\u001b[0m         early_stopping\u001b[39m=\u001b[39;49mearly_stopping,\n\u001b[1;32m   1693\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1694\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1695\u001b[0m         num_return_sequences\u001b[39m=\u001b[39;49mnum_return_sequences,\n\u001b[1;32m   1696\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1697\u001b[0m     )\n\u001b[1;32m   1699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1700\u001b[0m     \u001b[39m# TODO(Matt, Joao, Patrick) - add more sub-generation methods here\u001b[39;00m\n\u001b[1;32m   1701\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mBeam sampling is currently not implemented.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/transformers/generation_tf_utils.py:3003\u001b[0m, in \u001b[0;36mTFGenerationMixin.beam_search\u001b[0;34m(self, input_ids, max_length, pad_token_id, eos_token_id, length_penalty, early_stopping, logits_processor, num_return_sequences, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[1;32m   2999\u001b[0m \u001b[39mif\u001b[39;00m beam_search_cond_fn(\n\u001b[1;32m   3000\u001b[0m     cur_len, running_sequences, running_scores, sequences, scores, is_sent_finished, model_kwargs\n\u001b[1;32m   3001\u001b[0m ):\n\u001b[1;32m   3002\u001b[0m     maximum_iterations \u001b[39m=\u001b[39m max_length \u001b[39m-\u001b[39m cur_len\n\u001b[0;32m-> 3003\u001b[0m     cur_len, running_sequences, running_scores, sequences, scores, is_sent_finished, _ \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   3004\u001b[0m         beam_search_cond_fn,\n\u001b[1;32m   3005\u001b[0m         beam_search_body_fn,\n\u001b[1;32m   3006\u001b[0m         (cur_len, running_sequences, running_scores, sequences, scores, is_sent_finished, model_kwargs),\n\u001b[1;32m   3007\u001b[0m         maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   3008\u001b[0m     )\n\u001b[1;32m   3010\u001b[0m \u001b[39m# 6. prepare outputs\u001b[39;00m\n\u001b[1;32m   3011\u001b[0m \u001b[39m# Account for the edge-case where there are no finished sequences for a particular batch item. If so, return\u001b[39;00m\n\u001b[1;32m   3012\u001b[0m \u001b[39m# running sequences for that batch item.\u001b[39;00m\n\u001b[1;32m   3013\u001b[0m none_finished \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_any(is_sent_finished, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mwill be removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[39m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m, arg_name, arg_value, \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2507\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2331\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwhile_loop\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   2332\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2333\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2348\u001b[0m                   maximum_iterations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2349\u001b[0m                   name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2350\u001b[0m   \u001b[39m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2351\u001b[0m \n\u001b[1;32m   2352\u001b[0m \u001b[39m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2505\u001b[0m \n\u001b[1;32m   2506\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2507\u001b[0m   \u001b[39mreturn\u001b[39;00m while_loop(\n\u001b[1;32m   2508\u001b[0m       cond\u001b[39m=\u001b[39;49mcond,\n\u001b[1;32m   2509\u001b[0m       body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m   2510\u001b[0m       loop_vars\u001b[39m=\u001b[39;49mloop_vars,\n\u001b[1;32m   2511\u001b[0m       shape_invariants\u001b[39m=\u001b[39;49mshape_invariants,\n\u001b[1;32m   2512\u001b[0m       parallel_iterations\u001b[39m=\u001b[39;49mparallel_iterations,\n\u001b[1;32m   2513\u001b[0m       back_prop\u001b[39m=\u001b[39;49mback_prop,\n\u001b[1;32m   2514\u001b[0m       swap_memory\u001b[39m=\u001b[39;49mswap_memory,\n\u001b[1;32m   2515\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2516\u001b[0m       maximum_iterations\u001b[39m=\u001b[39;49mmaximum_iterations,\n\u001b[1;32m   2517\u001b[0m       return_same_structure\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2754\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m loop_var_structure \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(type_spec\u001b[39m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m   2752\u001b[0m                                         \u001b[39mlist\u001b[39m(loop_vars))\n\u001b[1;32m   2753\u001b[0m \u001b[39mwhile\u001b[39;00m cond(\u001b[39m*\u001b[39mloop_vars):\n\u001b[0;32m-> 2754\u001b[0m   loop_vars \u001b[39m=\u001b[39m body(\u001b[39m*\u001b[39;49mloop_vars)\n\u001b[1;32m   2755\u001b[0m   \u001b[39mif\u001b[39;00m try_to_pack \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(loop_vars, (\u001b[39mlist\u001b[39m, _basetuple)):\n\u001b[1;32m   2756\u001b[0m     packed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Education/NLP/Repository/env/lib/python3.10/site-packages/tensorflow/python/ops/control_flow_ops.py:2745\u001b[0m, in \u001b[0;36mwhile_loop.<locals>.<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2742\u001b[0m     loop_vars \u001b[39m=\u001b[39m (counter, loop_vars)\n\u001b[1;32m   2743\u001b[0m     cond \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (  \u001b[39m# pylint: disable=g-long-lambda\u001b[39;00m\n\u001b[1;32m   2744\u001b[0m         math_ops\u001b[39m.\u001b[39mlogical_and(i \u001b[39m<\u001b[39m maximum_iterations, orig_cond(\u001b[39m*\u001b[39mlv)))\n\u001b[0;32m-> 2745\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m i, lv: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, orig_body(\u001b[39m*\u001b[39;49mlv))\n\u001b[1;32m   2746\u001b[0m   try_to_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2748\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tensorflow.errors import InvalidArgumentError\n",
    "from generators import get_cnn_dm_both_generator\n",
    "\n",
    "output = []\n",
    "\n",
    "test_data_path = './dataset/chunked/test_000.bin'\n",
    "for article, abstract in get_cnn_dm_both_generator(test_data_path):\n",
    "    article_len = len(article)\n",
    "    try:\n",
    "        print(f'Summarizing text - len={article_len}')\n",
    "        summary = summarize(article)\n",
    "        output.append({\n",
    "            'article': article,\n",
    "            'abstract': abstract,\n",
    "            'bart': summary[0]['summary_text']\n",
    "        })\n",
    "    except InvalidArgumentError as err:\n",
    "        print(f'\\t ERROR')\n",
    "\n",
    "with open('bart_output.json', 'w') as fout:\n",
    "    json.dump(output, fout, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4fe221a22f9802ae2a050549df6cbcd7264e25be7971b2914a087a6bea67c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
