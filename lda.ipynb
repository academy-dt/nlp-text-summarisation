{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model training notebook\n",
    "\n",
    "We use an interactive notebook to train our LDA model.\n",
    "\n",
    "The notebook uses custom-modules defined in other files, but to prevent ourselves from re-loading the data during training, it is easier to use a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import config\n",
    "config.fileConfig('./logging.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_path = './dictionary'\n",
    "tf_idf_path = './tf_idf'\n",
    "test_path = './dataset/chunked/test_*.bin'\n",
    "data_path = './dataset/chunked/train_*.bin'\n",
    "model_path = './model/grid-xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-computed resources\n",
    "\n",
    "Dictionary and TF-IDF models are already precomputed and stored in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary.load(dictionary_path)\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "tf_idf = TfidfModel.load(tf_idf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the corpus (CNN/DailyMail)\n",
    "\n",
    "Using the TF-IDF generator automatically uses the entire chain of generators: Pre-processor -> BOW -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators import get_cnn_dm_article_generator, get_tf_idf_generator\n",
    "cnn_dm_gen = get_cnn_dm_article_generator(data_path)\n",
    "gen = get_tf_idf_generator(cnn_dm_gen, dictionary, tf_idf)\n",
    "corpus = list(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search to find best LDA model\n",
    "\n",
    "NOTE: We actually generate and store all the models in memory, so it's easier to examining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Grid searching for best model')\n",
    "params_grid = {\n",
    "    'num_topics': [33, 66, 100],\n",
    "    'decay': [0.85, 1],\n",
    "    'passes': [2],\n",
    "    'alpha': [0.05, 0.07, 0.1],\n",
    "    'eta': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "from lda_trainer import train_cnn_dm_models\n",
    "trainers = train_cnn_dm_models(corpus, dictionary, params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators import get_cnn_dm_article_generator, get_bow_generator\n",
    "test_cnn_dm_gen = get_cnn_dm_article_generator(test_path)\n",
    "test_gen = get_bow_generator(test_cnn_dm_gen, dictionary)\n",
    "test_corpus = list(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex = [trainer.model.log_perplexity(test_corpus) for trainer in trainers]\n",
    "best_index = perplex.index(min(perplex))\n",
    "logging.info(perplex, '-->', f'min: {best_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the models into an \"archive\" for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root_dir = f'./model_archive'\n",
    "os.mkdir(root_dir)\n",
    "\n",
    "for idx, trainer in enumerate(trainers):\n",
    "    model_dir = f'{root_dir}/{idx}'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "\n",
    "    with open(f'{model_dir}/params.txt', 'w') as fout:\n",
    "        json.dump(trainer.params, fout, indent=4)\n",
    "\n",
    "    with open(f'{model_dir}/perplex.txt', 'w') as fout:\n",
    "        fout.write(f'{perplex[idx]}')\n",
    "\n",
    "    trainer.model.save(f'{model_dir}/grid-xxx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a single model, the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trainer = trainers[best_index]\n",
    "logging.info(f'Best model [{best_trainer.params}]')\n",
    "logging.info(f'Saving model [{model_path}]')\n",
    "best_trainer.model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4fe221a22f9802ae2a050549df6cbcd7264e25be7971b2914a087a6bea67c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
