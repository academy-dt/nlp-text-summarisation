{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model training notebook\n",
    "\n",
    "We use an interactive notebook to train our LDA model.\n",
    "\n",
    "The notebook uses custom-modules defined in other files, but to prevent ourselves from re-loading the data during training, it is easier to use a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import config\n",
    "config.fileConfig('./logging.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_path = './dictionary'\n",
    "tf_idf_path = './tf_idf'\n",
    "test_path = './dataset/chunked/test_*.bin'\n",
    "data_path = './dataset/chunked/train_*.bin'\n",
    "model_path = './model/grid-xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-computed resources\n",
    "\n",
    "Dictionary and TF-IDF models are already precomputed and stored in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dictionary = Dictionary.load(dictionary_path)\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "tf_idf = TfidfModel.load(tf_idf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the corpus (CNN/DailyMail)\n",
    "\n",
    "Using the TF-IDF generator automatically uses the entire chain of generators: Pre-processor -> BOW -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators import get_cnn_dm_article_generator, get_tf_idf_generator\n",
    "cnn_dm_gen = get_cnn_dm_article_generator(data_path)\n",
    "gen = get_tf_idf_generator(cnn_dm_gen)\n",
    "corpus = list(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search to find best LDA model\n",
    "\n",
    "NOTE: We actually generate and store all the models in memory, so it's easier to examining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('Grid searching for best model')\n",
    "params_grid = {\n",
    "    'num_topics': [33, 66, 100],\n",
    "    'decay': [0.85, 1],\n",
    "    'passes': [2],\n",
    "    'alpha': [0.05, 0.07, 0.1],\n",
    "    'eta': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "from lda_trainer import train_cnn_dm_models\n",
    "trainers = train_cnn_dm_models(corpus, dictionary, params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators import get_cnn_dm_article_generator, get_bow_generator\n",
    "test_cnn_dm_gen = get_cnn_dm_article_generator(test_path)\n",
    "test_gen = get_bow_generator(test_cnn_dm_gen, dictionary)\n",
    "test_corpus = list(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models against the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplex = [trainer.model.log_perplexity(test_corpus) for trainer in trainers]\n",
    "logging.info(perplex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the best model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trainer = trainers[-1] # The last model was the best one\n",
    "logging.info(f'Best model [{best_trainer.params}]')\n",
    "logging.info(f'Saving model [{model_path}]')\n",
    "best_trainer.model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
