{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Sync repo to your Google Drive account"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2201,"status":"ok","timestamp":1660415153990,"user":{"displayName":"Shira Moscovitch","userId":"17618892035887104527"},"user_tz":-180},"id":"DnlipSMuHvkP","outputId":"740349ee-8fe9-4be0-f75b-3aa55d46e94a"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","\n","#!git clone https://github.com/academy-dt/nlp-text-summarisation '/content/drive/MyDrive/MS_DS/NLP/Final project/nlp-text-summarisation'\n","#os.chdir('/content/drive/MyDrive/MS_DS/NLP/Final project/nlp-text-summarisation')\n","\n","!git clone https://github.com/academy-dt/nlp-text-summarisation '/content/drive/MyDrive/NLP/nlp-text-summarisation'\n","os.chdir('/content/drive/MyDrive/NLP/nlp-text-summarisation')\n","\n","!git submodule init\n","!git submodule update"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9783,"status":"ok","timestamp":1660415176932,"user":{"displayName":"Shira Moscovitch","userId":"17618892035887104527"},"user_tz":-180},"id":"2ZADRRpBIRby","outputId":"3014808c-542f-4692-d2b4-c3485ae166cf"},"outputs":[],"source":["%pip install transformers\n","%pip install torch\n","%pip install rouge"]},{"cell_type":"markdown","metadata":{},"source":["### Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23743,"status":"ok","timestamp":1660415200649,"user":{"displayName":"Shira Moscovitch","userId":"17618892035887104527"},"user_tz":-180},"id":"a0ebxhzMGulA"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n","import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-xsum\")\n","model.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Run model and summarize text"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1660415208829,"user":{"displayName":"Shira Moscovitch","userId":"17618892035887104527"},"user_tz":-180},"id":"LQpFTNMhVPGk"},"outputs":[],"source":["def summarize(text):\n","    # Using values from the pegasus-xsum repo:\n","    # Tokenizer config: https://huggingface.co/google/pegasus-xsum/blob/main/tokenizer_config.json\n","    # Model config: https://huggingface.co/google/pegasus-xsum/blob/main/config.json\n","    preprocess_text = text.strip().replace(\"\\n\",\"\")\n","    tokenized_text = tokenizer.encode(preprocess_text, return_tensors=\"pt\", max_length=512).to(device)\n","    summary_ids = model.generate(tokenized_text, max_length=64)\n","    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":425602,"status":"ok","timestamp":1660417169915,"user":{"displayName":"Shira Moscovitch","userId":"17618892035887104527"},"user_tz":-180},"id":"Sn5Ub5b8Gs68","outputId":"0044bd3b-69b3-4d14-c114-e6ff91d00ed2"},"outputs":[],"source":["import json\n","from generators import get_cnn_dm_both_generator\n","\n","output = []\n","\n","i = 0\n","test_data_path = '/content/drive/MyDrive/test_dataset/test_000.bin'\n","for article, abstract in get_cnn_dm_both_generator(test_data_path):\n","    i += 1\n","    print(f'#{i}')\n","\n","    bart_abstract = summarize(article)\n","    output.append({\n","        'article': article,\n","        'abstract': abstract,\n","        'pegasus_abstract': bart_abstract\n","    })\n","\n","with open('pegasus_output_000.json', 'w') as fout:\n","    json.dump(output, fout, indent=2)"]},{"cell_type":"markdown","metadata":{"id":"VZrpchwvJRGU"},"source":["### ROUGE evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":980,"status":"ok","timestamp":1660417497079,"user":{"displayName":"Shira Moscovitch","userId":"17618892035887104527"},"user_tz":-180},"id":"tAl0Dtv127TE","outputId":"7a510f5b-b21c-4427-99cf-e2b5be2f83be"},"outputs":[],"source":["from rouge import Rouge\n","\n","summaries = [x['pegasus_abstract'] for x in output]\n","abstracts = [x['abstract'] for x in output]\n","\n","rouge = Rouge()\n","scores = rouge.get_scores(summaries, abstracts)\n","print(scores)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"pegasus_xsum.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.4 ('env': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"e4fe221a22f9802ae2a050549df6cbcd7264e25be7971b2914a087a6bea67c1c"}}},"nbformat":4,"nbformat_minor":0}
